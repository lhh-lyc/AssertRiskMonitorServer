spring:
  # jackson时间格式化
  jackson:
    time-zone: GMT+8
    date-format: yyyy-MM-dd HH:mm:ss
  sleuth:
    sampler:
      percentage: 1
  datasource:
    type: com.alibaba.druid.pool.DruidDataSource
    driver-class-name: com.mysql.jdbc.Driver
    url: jdbc:mysql://localhost:3306/asset_risk?allowMultiQueries=true&useUnicode=true&characterEncoding=UTF-8&useOldAliasMetadataBehavior=true&rewriteBatchedStatements=true
    username: root
    password: 123456

# Redis 配置
  redis:
    host: localhost
    port: 6379
    password: 123456
    pool:
      max-idle: 1000
      min-idle: 0
      max-active: 1000
      max-wait: -1
    timeout: 5000
  #flyway
  flyway:
    baseline-on-migrate: true
    locations: classpath:db/migration
    schemas: schema
    #baseline-version: 1 #低于该版本号的sql全部禁用 - 测试使用
    out-of-order: false #对于开发环境, 可能是多人协作开发, 很可能先 apply 了自己本地的最新 SQL 代码, 然后发现其他同事早先时候提交的 SQL 代码还没有 apply, 所以 开发环境应该设置 spring.flyway.outOfOrder=true, 这样 flyway 将能加载漏掉的老版本 SQL 文件; 而生产环境应该设置 spring.flyway.outOfOrder=false
  rabbitmq:
    port: 5672
    host: localhost
    username: guest
    password: guest
#这个配置是保证提供者确保消息推送到交换机中，不管成不成功，都会回调
    publisher-confirm-type: correlated
    #保证交换机能把消息推送到队列中
    publisher-returns: true
    virtual-host: /
    #这个配置是保证消费者会消费消息，手动确认
    listener:
      simple:
        acknowledge-mode: manual
    template:
      mandatory: true

eureka:
  client:
    serviceUrl:
      defaultZone: http://localhost:10001/eureka/
  instance:
    prefer-ip-address: true
    instance-id: ${spring.cloud.client.ip-address}:${server.port}

server-setting:
  is_prod: 0
  host_name: 180.110.202.160
  user_name: root
  pwd: Lhh110112
  exec_timeout: 6000

dir-setting:
  tool-dir: /opt/assertRiskMonitorServer/tools/

mqtt-setting:
  exchange: amp.topic
  host-route-key: key.host
  scanning-host-pub-topic: scanningHostData
  ip-route-key: key.ip
  scanning-ip-pub-topic: scanningIpData
  hole-route-key: key.hole
  scanning-hole-pub-topic: scanningHoleData
  exit-hole-route-key: key.exitHole
  exit-hole-pub-topic: exitHoleData
  concurrent_consumers: 8
  maxConcurrent_consumers: 8
  prefetch_count: 1

my-config:
  minio:
    endpoint: http://49.235.104.19:9000
    accesskey: minioadmin
    secretkey: minioadmin
  upload:
    defFolder: def
    defBucket: assertfiles
  file:
    nuclei-folder: /root/nuclei-templates/custom
    afrog-folder: /root/afrog-pocs/custom
    xray-folder: /root/xray-pocs/custom